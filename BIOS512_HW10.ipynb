{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d684172-4b94-42cf-bda2-e11952420d86",
   "metadata": {},
   "source": [
    "# Homework 10\n",
    "#### Course Notes\n",
    "**Language Models:** https://github.com/rjenki/BIOS512/tree/main/lecture17  \n",
    "**Unix:** https://github.com/rjenki/BIOS512/tree/main/lecture18  \n",
    "**Docker:** https://github.com/rjenki/BIOS512/tree/main/lecture19"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d839a5ba-62f4-4699-baea-018afda70786",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "#### Make a language model that uses ngrams and allows the user to specify start words, but uses a random start if one is not specified."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef37d3a-a6ad-42ae-9e16-7d7338c9ce49",
   "metadata": {},
   "source": [
    "#### a) Make a function to tokenize the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d7f2705f-94b8-419a-b335-5e2ee8b28c7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The downloaded binary packages are in\n",
      "\t/var/folders/yh/x49cjjwn6w1c2sjv6g2r8ktm0000gn/T//RtmplUt6jk/downloaded_packages\n"
     ]
    }
   ],
   "source": [
    "install.packages(c(\n",
    "  \"httr\",\n",
    "  \"jsonlite\",\n",
    "  \"tokenizers\",\n",
    "  \"stringr\",\n",
    "  \"R6\",\n",
    "  \"digest\",\n",
    "  \"viridis\"\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0af09146-8b24-4a4f-9e29-88008de4a8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "library(httr)\n",
    "library(tokenizers)\n",
    "\n",
    "tokenize_text <- function(text) {\n",
    "    tokenizers::tokenize_words(text, lowercase=TRUE, strip_punct=TRUE)[[1]]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86145513-294b-4894-a02c-8ae60e2c616e",
   "metadata": {},
   "source": [
    "#### b) Make a function generate keys for ngrams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bdfd0f05-d1a0-4135-b9a2-54f5c23ed2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "key_from <- function(ngram, sep = \"\\x1f\") {\n",
    "    paste(ngram, collapse=sep)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52988c2c-b230-467f-b519-72bc85b93b43",
   "metadata": {},
   "source": [
    "#### c) Make a function to build an ngram table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9ce4be4c-c428-4526-afd7-f63f272a40a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "build_ngram_table <- function(tokens, n, sep = \"\\x1f\") {\n",
    "    if (length(tokens) < n) return(new.env(parent = emptyenv()))\n",
    "    tbl <- new.env(parent = emptyenv())\n",
    "    for (i in seq_len(length(tokens) - n + 1L)) {\n",
    "        ngram <- tokens[i:(i + n - 2L)]\n",
    "        next_word <- tokens[i + n - 1L]\n",
    "        key <- paste(ngram, collapse = sep)\n",
    "        counts <- if (!is.null(tbl[[key]])) tbl[[key]] else integer(0)\n",
    "        if (next_word %in% names(counts)) {\n",
    "            counts[[next_word]] <- counts[[next_word]] + 1L\n",
    "        } else {\n",
    "            counts[[next_word]] <- 1L\n",
    "        }\n",
    "        tbl[[key]] <- counts\n",
    "    }\n",
    "    tbl\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca6db37-abce-4705-9784-e1b898174f00",
   "metadata": {},
   "source": [
    "#### d) Function to digest the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0fa79f91-81c4-4174-ba95-8253278f58ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "digest_text <- function(text, n) {\n",
    "    tokens <- tokenize_text(text)\n",
    "    build_ngram_table(tokens, n)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53fff313-0f13-479b-94df-7588c19fdd3d",
   "metadata": {},
   "source": [
    "#### e) Function to digest the url."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5a52fa54-29e6-4297-abd6-d9cb0543d8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "digest_url <- function(url, n) {\n",
    "    res <- httr::GET(url)\n",
    "    txt <- httr::content(res, as = \"text\", encoding = \"UTF-8\")\n",
    "    digest_text(txt,n)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4aa4e73-ee6f-4569-9a54-9d7f7eb3f80a",
   "metadata": {},
   "source": [
    "#### f) Function that gives random start."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f3ce5675-2202-40c4-a25f-a8bb67aaedd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_start <- function(tbl, sep = \"\\x1f\") {\n",
    "    keys <- ls(envir = tbl, all.names=TRUE)\n",
    "    if (length(keys)==0) stop(\"No n-grams available. Digest text first.\")\n",
    "    picked <- sample(keys, 1)\n",
    "    strsplit(picked, sep, fixed=TRUE)[[1]]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e998fb24-f2d6-41bc-a751-1f6accd3411f",
   "metadata": {},
   "source": [
    "#### g) Function to predict the next word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "710a1c35-b0a1-4175-b005-4e4eb4d9e251",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_next_word <- function(tbl, ngram, sep = \"\\x1f\") {\n",
    "    key <- paste(ngram, collapse = sep)\n",
    "    counts <- if(!is.null(tbl[[key]])) tbl[[key]] else integer(0)\n",
    "    if (length(counts) == 0) return(NA_character_)\n",
    "    sample(names(counts), size=1, prob=as.numeric(counts))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "347f4002-4932-42c4-a4af-8689293a5857",
   "metadata": {},
   "source": [
    "#### h) Function that puts everything together. Specify that if the user does not give a start word, then the random start will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4e99cbcd-d1ef-415d-827e-47c6232c7bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_ngram_generator <- function(tbl, n, sep = \"\\x1f\") {\n",
    "    force(tbl); n <- as.integer(n); force(sep)\n",
    "    function(start_words = NULL, length = 10L) {\n",
    "        if ((is.null(start_words)) || length(start_words) != n - 1L) {\n",
    "            start_words <- random_start(tbl, sep=sep)\n",
    "        }\n",
    "        word_sequence <- start_words\n",
    "        for (i in seq_len(max(0L, length - length(start_words)))) {\n",
    "            ngram <- tail(word_sequence, n - 1L)\n",
    "            next_word <- predict_next_word(tbl, ngram, sep=sep)\n",
    "            if (is.na(next_word)) break\n",
    "            word_sequence <- c(word_sequence, next_word)\n",
    "        }\n",
    "        paste(word_sequence, collapse= \" \")\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b742c67-907c-4bc7-8df1-c84fa65a7554",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "#### For this question, set `seed=2025`.\n",
    "#### a) Test your model using a text file of [Grimm's Fairy Tails](https://www.gutenberg.org/cache/epub/2591/pg2591.txt)\n",
    "#### i) Using n=3, with the start word(s) \"the king\", with length=15. \n",
    "#### ii) Using n=3, with no start word, with length=15."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8cbdb034-fae1-4f76-ad72-a2c74785af3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the king has forbidden me to marry another husband am not i shall ride upon"
     ]
    }
   ],
   "source": [
    "set.seed(2025)\n",
    "url <- \"https://www.gutenberg.org/cache/epub/2591/pg2591.txt\"\n",
    "tbl3 <- digest_url(url, n=3)\n",
    "gen3 <- make_ngram_generator(tbl3, n=3)\n",
    "output <- gen3(start_words = c(\"the\", \"king\"), length = 15)\n",
    "cat(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fa431246-e0ac-4ff4-bd63-5638faff2856",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"spread the jam over it spread its wings and crying here comes our hobblety jib\"\n"
     ]
    }
   ],
   "source": [
    "set.seed(2025)\n",
    "url <- \"https://www.gutenberg.org/cache/epub/2591/pg2591.txt\"\n",
    "tbl3 <- digest_url(url, n=3)\n",
    "gen3 <- make_ngram_generator(tbl3, n=3)\n",
    "print(gen3(length=15))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e04b167-7f2c-4e0f-88e7-86ba5e8d74cc",
   "metadata": {},
   "source": [
    "#### b) Test your model using a text file of [Ancient Armour and Weapons in Europe](https://www.gutenberg.org/cache/epub/46342/pg46342.txt)\n",
    "#### i) Using n=3, with the start word(s) \"the king\", with length=15. \n",
    "#### ii) Using n=3, with no start word, with length=15."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "000f9a0e-9448-401d-ba20-15f44b71b9d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the king he added to the entire exclusion of the swords were made prisoners the"
     ]
    }
   ],
   "source": [
    "set.seed(2025)\n",
    "url <- \"https://www.gutenberg.org/cache/epub/46342/pg46342.txt\"\n",
    "tbl3 <- digest_url(url, n=3)\n",
    "gen3 <- make_ngram_generator(tbl3, n=3)\n",
    "output <- gen3(start_words = c(\"the\", \"king\"), length = 15)\n",
    "cat(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3d075a5c-cbff-461f-83e4-ded39e5bfebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"lamentation de lemburn came forth completely armed after the fashion of this may be seen\"\n"
     ]
    }
   ],
   "source": [
    "set.seed(2025)\n",
    "url <- \"https://www.gutenberg.org/cache/epub/46342/pg46342.txt\"\n",
    "tbl3 <- digest_url(url, n=3)\n",
    "gen3 <- make_ngram_generator(tbl3, n=3)\n",
    "print(gen3(length=15))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25fb37ad-8e7c-4e62-afc0-ba46d46401fc",
   "metadata": {},
   "source": [
    "#### c) Explain in 1-2 sentences the difference in content generated from each source."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe0d2af-446c-4fad-96d4-c2583a46116d",
   "metadata": {},
   "source": [
    "Using the n=3 model with a specificed start word, constrains the text to a particular context. However, without using a start word, the text produces a random start with unique sequences. The difference in words used it based on the difference in material and stories. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e45972-f441-4d07-9073-fcddd6146cbd",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "#### a) What is a language learning model? \n",
    "#### b) Imagine the internet goes down and you can't run to your favorite language model for help. How do you run one locally?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8b9ee0-551d-4f00-83f6-d3a247b17359",
   "metadata": {},
   "source": [
    "A language learning model is a model that predicts the following word in a sequence based on the context and using probability. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8adeb9-8d85-4c7c-b2ce-859b63865cb9",
   "metadata": {},
   "source": [
    "OLLAMA allows you to run language models locally. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b85a743b-f814-4a53-96e6-8bccb3d34ab8",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "#### Explain what the following vocab words mean in the context of typing `mkdir project` into the command line. If the term doesn't apply to this command, give the definition and/or an example.\n",
    "| Term | Meaning |  \n",
    "|------|---------|\n",
    "| **Shell** | the program that interprets the commands and executes them |\n",
    "| **Terminal emulator** | the application that applies a text interface to interact with the shell |\n",
    "| **Process** | an instance of a running program  |\n",
    "| **Signal** | a message sent to a process to tell it to do something  |\n",
    "| **Standard input** | the default way a process receives input |\n",
    "| **Standard output** | the default destination for output |\n",
    "| **Command line argument** | extra information passed to a command |\n",
    "| **The environment** | a set of variables and settings available to process |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1332ff27-ca3f-4f7e-b4b9-07ead0358dd2",
   "metadata": {},
   "source": [
    "## Question 5\n",
    "#### Consider the following command `find . -iname \"*.R\" | xargs grep read_csv`.\n",
    "#### a) What are the programs?\n",
    "#### b) Explain what this command is doing, part by part."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972d0f51-49ab-4004-b522-480d2ed8e908",
   "metadata": {},
   "source": [
    "a) the programs include find, xargs and grep "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b90d67-9876-44f8-ac6b-91ce7f69fca2",
   "metadata": {},
   "source": [
    "b) first, the command is searching for files in the directory looking for files ending in .R and is taking the output of this to send it to the command xargs, which is reading the list of .R files and is converting them into arguments to grep, which then searches for the text \"read_csv\" within each file and outputs them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69771ac7-865e-4d82-aa25-a39e7c1ab095",
   "metadata": {},
   "source": [
    "## Question 6\n",
    "#### Install Docker on your machine. See [here](https://github.com/rjenki/BIOS512/blob/main/lecture18/docker_install.md) for instructions. \n",
    "#### a) Show the response when you run `docker run hello-world`.\n",
    "#### b) Access Rstudio through a Docker container. Set your password and make sure your files show up on the Rstudio server. Type the command and the output you get below.\n",
    "#### c) How do you log in to the RStudio server?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c2f072a-378a-4f29-970e-176d2ac0acf0",
   "metadata": {},
   "source": [
    "a) Hello from Docker!\n",
    "This message shows that your installation appears to be working correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd3990c-03d9-4f92-8523-214f139ea5d6",
   "metadata": {},
   "source": [
    "b) docker run -d -p 8787:8787 \\\n",
    "  -e PASSWORD=christou3 \\\n",
    "  -v /Users/angelchristou/my-first-binder:/home/rstudio/files \\\n",
    "  rocker/rstudio\n",
    "\n",
    "e177d270eea239b10ca594c804603975009f0b25d56c6c337663a66f7274664d\n",
    "docker: Error response from daemon: failed to set up container networking: driver failed programming external connectivity on endpoint tender_mahavira (0483afac67ad56eaa0abaf7bf6eb4ca70723802cc7086cc752e3f39de6059c07): Bind for 0.0.0.0:8787 failed: port is already allocated\n",
    "\n",
    "Run 'docker run --help' for more information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c7ed63-d44f-4849-ad4d-9c87f0f29583",
   "metadata": {},
   "source": [
    "c) type rstudio for the username and your personalized password. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb36a1b4-b635-45a7-87f7-fb06e7df55c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
